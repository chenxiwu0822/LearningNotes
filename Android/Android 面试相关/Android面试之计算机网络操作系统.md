# 计算机网络操作系统

| 时间       | 版本  | 说明           |
| ---------- | ----- | -------------- |
| 2020.10.15 | 0.0.1 | 初创，结构输入 |
| 2021.01.18 | 0.0.2 | 初版完成       |

## 网络

### 一、网络体系

#### 1. 网页中输入url，到渲染整个界面的整个过程，以及中间用了什么协议？

1）过程分析：主要分为三步

- `DNS解析`。用户输入url后，需要通过DNS解析找到域名对应的ip地址，有了ip地址才能找到服务器端。首先会查找**浏览器缓存**，是否有对应的dns记录。再继续按照操作**系统缓存—路由缓存—isp的dns服务器—根服务器**的顺序进行DNS解析，直到找到对应的ip地址。

- `客户端（浏览器）和服务器交互`。浏览器根据解析到的ip地址和端口号发起HTTP请求，请求到达传输层，这里也就是TCP层，开始三次握手建立连接。服务器收到请求后，发送相应报文给客户端（浏览器），客户端收到相应报文并进行解析，得到html页面数据，包括html，js，css等。
- `客户端（浏览器）解析html数据`，构建DOM树，再构造呈现树（render树），最终绘制到浏览器页面上。

2）其中涉及到TCP/IP协议簇，包括DNS，TCP，IP，HTTP协议等等。

#### 2. 具体介绍下TCP/IP

TCP/IP一般指的是TCP/IP协议簇，主要包括了多个不同网络间实现信息传输涉及到的各种协议
主要包括以下几层：

- 应用层：主要提供数据和服务。比如HTTP，FTP，DNS等
- 传输层：负责数据的组装，分块。比如TCP，UDP等
- 网络层：负责告诉通信的目的地，比如IP等
- 数据链路层：负责连接网络的硬件部分，比如以太网，WIFI等

### 二、TCP

#### 1. TCP三次握手?四次挥手?

重要标志位：

- ACK：TCP协议规定，只有ACK=1时有效，也规定连接建立后所有发送的报文的ACK必须为1。

- SYN(SYNchronization) ：在连接建立时用来同步序号。当SYN=1而ACK=0时，表明这是一个连接请求报文。对方若同意建立连接，则应在响应报文中使SYN=1和ACK=1. 因此, SYN置1就表示这是一个连接请求或连接接受报文。

- FIN （finis）即完，终结的意思， 用来释放一个连接。当 FIN = 1 时，表明此报文段的发送方的数据已经发送完毕，并要求释放连接。

三次握手、四次挥手过程：

![img](https://api2.mubu.com/v3/document_image/5cf012ac-7f38-45d9-9715-62636bc270bf-2297223.jpg)

- 三次握手：

  - 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，seq为x；然后，客户端进入SYN_SEND状态，等待服务器的确认；

  - 第二次握手：服务器收到SYN报文段，需要对这个SYN报文段进行确认，设置ACK为x+1(即seq+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，seq为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态；

  - 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将ACK设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。

- 四次挥手：

  - 第一次分手：主机1（可以使客户端，也可以是服务器端），设置seq和ACK，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态，这表示主机1没有数据要发送给主机2了；

  - 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，ACK为seq加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求；

  - 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；

  - 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。

- “三次握手”的目的：

  “为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”。主要目的防止server端一直等待，浪费资源。换句话说，即是为了**保证服务端能收接受到客户端的信息并能做出正确的应答而进行前两次(第一次和第二次)握手**，为了**保证客户端能够接收到服务端的信息并能做出正确的应答而进行后两次(第二次和第三次)握手**。

- “四次挥手”的原因：

  因为tcp是全双工模式，接收到**FIN时意味将没有数据再发来，但是还是可以继续发送数据**。

#### 2. TCP的三次握手? 四次挥手过程？

三次握手大致意思就是：

- `Client`：我要建立连接了
- `Server`：我收到你的建立消息了，我也要建立连接了
- `Client`：收到你要建立连接的消息了

`Client`和`Server`之后连接建立

四次挥手大致意思就是：

- `Client`：我要断开连接了
- `Server`：我收到你的消息了
- `Server`：我也要断开连接了
- `Client`：收到你要断开连接的消息了

之后`Client`等待两个`MSL`(数据包在网络上生存的最长时间)，如果服务端没有回消息就彻底断开了。

#### 3. TCP和UDP有什么区别？

- `TCP`：基于字节流、面向连接、可靠、能够进行全双工通信，除此以外，还能进行流量控制和拥塞控制，不过效率略低
- `UDP`：基于报文、面向无连接、不可靠，但是传输效率高。

总的来说，TCP适用于传输效率要求低，准确性要求高或要求有连接。而UDP适用于对准确性要求较低，传输效率要求较高的场景，比如语音通话、直播等。

#### 4. TCP为什么是一种可靠的协议？如何做到流量控制和拥塞控制？

- TCP可靠：是因为可以做到数据包发送的有序、无差错和无重复。
- 流量控制：是通过**滑动窗口**实现的，因为发送发和接收方消息发送速度和接收速度不一定对等，所以需要一个滑动窗口来平衡处理效率，并且保证没有差错和有序的接收数据包。
- 拥塞控制：**慢开始**和**拥塞避免**、**快重传**和**快恢复算法**。这写算法主要是为了适应网络中的带宽而作出的调整。

##### (1) TCP流量控制

如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓**流量控制**就是让发送方的发送速率不要太快，要让接收方来得及接收。

利用**滑动窗口机制**可以很方便地在TCP连接上实现对发送方的流量控制。

设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd = 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。**大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。**

[![img](https://camo.githubusercontent.com/c0a0c2894760d9b6b42f58828a66fe08e4f3103c/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d383436323330623262393165353639362e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/c0a0c2894760d9b6b42f58828a66fe08e4f3103c/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d383436323330623262393165353639362e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd = 300 ，第二次又减到了 rwnd = 100 ，最后减到 rwnd = 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK = 1 ，只有在ACK=1时确认号字段才有意义。

TCP为每一个连接设有一个持续计时器(persistence timer)。当TCP连接中的发送方收到接收方的零窗口通知时，发送方就启动持续计时器。若持续计时器设置的时间到期，发送方就发送一个零窗口控测报文段（携1字节的数据）给接收方。如果接收方可以接收数据，就重新开始发送数据；如果接收方不能接收数据，就重新设置持续计时器。

##### (2) TCP拥塞控制

**慢开始和拥塞避免** 

发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。

发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。

**慢开始算法：**

当主机开始发送数据时，如果立即有大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。

因此，较好的方法是，先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。

通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS（Maximum Segment Size，最大报文长度）的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值（底数为2的指数增长规律）。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。

[![img](https://camo.githubusercontent.com/dd1c21dd166f40b86c5e04ec334941c73fb8b340/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d343730323335623165393964383131312e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/dd1c21dd166f40b86c5e04ec334941c73fb8b340/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d343730323335623165393964383131312e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

每经过一个传输轮次，拥塞窗口 cwnd 就加倍。

**一个传输轮次所经历的时间其实就是往返时间RTT。**

不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。

另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。

为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下：

- 当 cwnd < ssthresh 时，使用上述的慢开始算法。
- 当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。
- 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。

**拥塞避免**

让拥塞窗口cwnd缓慢地增大，即每经过**一个往返时间RTT**就把发送方的**拥塞窗口cwnd加1，而不是加倍**。这样拥塞窗口cwnd按线性增长规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。

![img](https://camo.githubusercontent.com/8d5f6b52d406e50260e6af7731a53de6f0895379/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d386262656565313431353335653132352e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。

这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。

如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。

[![img](https://camo.githubusercontent.com/79e8ec1d9e98c8c2b167675c1f9449cf7270cc34/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d346361353632303435626539333530642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/79e8ec1d9e98c8c2b167675c1f9449cf7270cc34/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d346361353632303435626539333530642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

**快重传和快恢复**

**快重传**

快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。

[![img](https://camo.githubusercontent.com/22f1bd2941a7d86dfb9207322d6bfaff75cd94e5/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d336534663963353835323030656431382e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/22f1bd2941a7d86dfb9207322d6bfaff75cd94e5/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d336534663963353835323030656431382e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。

显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。

但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了接收方的四个对M2的确认，其中后三个都是重复确认。

**快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。**

由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。

**快恢复**

与快重传配合使用的还有快恢复算法，其过程有以下两个要点：

- 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。

- 与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。

  [![img](https://camo.githubusercontent.com/4cf7b67d6bd8d94d41f40279fd360b9f0a7d6e25/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d386530626633633263393535346635642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)](https://camo.githubusercontent.com/4cf7b67d6bd8d94d41f40279fd360b9f0a7d6e25/687474703a2f2f75706c6f61642d696d616765732e6a69616e7368752e696f2f75706c6f61645f696d616765732f333938353536332d386530626633633263393535346635642e706e673f696d6167654d6f6772322f6175746f2d6f7269656e742f7374726970253743696d61676556696577322f322f772f31323430)

### 2. HTTP

#### 5. TCP的三次握手过程，为什么需要三次，而不是两次或者四次？



![三次握手](https://user-gold-cdn.xitu.io/2020/4/24/171ab7a755aa564f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

TCP协议是全双工通信。三次握手确保双方连接都能建立。

只发送两次，服务端是不知道自己发送的消息能不能被客户端接收到。 因为TCP握手是三次，所以此时双方都已经知道自己发送的消息能够被对方收到，所以，第四次的发送就显得多余了。

#### 6. TCP的三次握手和四次挥手，为什么不是两次握手？为什么挥手多一次呢？

客户端简称A，服务器端简称B

 1）TCP建立连接需要三次握手

- A向B表示想跟B进行连接（A发送`syn`包，A进入`SYN_SENT`状态）
- B收到消息，表示我也准备好和你连接了（B收到`syn`包，需要确认`syn`包，并且自己也发送一个`syn`包，即发送了`syn+ack`包，B进入`SYN_RECV`状态）
- A收到消息，并告诉B表示我收到你也准备连接的信号了（A收到`syn+ack`包，向服务器发送确认包`ack`，AB进入`established`状态）开始连接。

2）TCP断开连接需要四次挥手

- A向B表示想跟B断开连接（A发送`fin`，进入`FIN_WAIT_1`状态）
- B收到消息，但是B消息没发送完，只能告诉A我收到你的断开连接消息（B收到fin，发送ack，进入`CLOSE_WAIT`状态）
- 过一会，B数据发送完毕，告诉A，我可以跟你断开了（B发送fin，进入`LAST_ACK`状态）
- A收到消息，告诉B，可以他断开（A收到fin，发送ack，B进入`close`d状态）

3）**为什么挥手多一次？**
 其实正常的断开和连接都是需要`四次`：

- A发消息给B
- B反馈给A表示正确收到消息
- B发送消息给A
- A反馈给B表示正确收到消息。

但是连接中，第二步和第三步是`可以合并`的，因为连接之前A和B是无联系的，所以没有其他情况需要处理。而断开的话，因为之前两端是正常连接状态，所以第二步的时候不能保证B之前的消息已经发送完毕，所以不能马上告诉A要断开的消息。这就是连接为什么可以少一步的原因。

4）**为什么连接需要三次，而不是两次？**

 正常来说，我给你发消息，你告诉我能收到，不就代表我们之前通信是正常的吗？

- 简单回答就是，`TCP是双向通信协议`，如果两次握手，不能保证B发给A的消息正确到达。

TCP 协议为了实现可靠传输， 通信双方需要判断自己已经发送的数据包是否都被接收方收到， 如果没收到， 就需要重发。

5）**TCP是怎么保证可靠传输的？**

- `序列号和确认号`。比如连接的一方发送一段80byte数据，会带上一个序列号，比如101。接收方收到数据，回复确认号181（180+1），这样下一次发送消息就会从181开始发送了。

### 三、UDP

#### 1. UDP是全双工吗？

所谓全双工，半双工，单工是指面向连接时才有的说法，如果不是面向连接的，没有一个确定的连接的话，怎么会出现半双工这种只准一个来或者一个去的说法呢？

UDP支持一对一，一对多，多对一和多对多的交互通信。如果一定要涉及到全双工的话，大概理解为不仅提供全双工，甚至提供全**多**工服务，只是UDP是不可靠的服务而已。

#### 2. 如何设计在 UDP 上层保证 UDP 的可靠性传输？

传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式。如不考虑拥塞处理，可靠UDP的简单设计如下：

- 1、添加seq/ack机制，确保数据发送到对端
- 2、添加发送和接收缓冲区，主要是用户超时重传。
- 3、添加超时重传机制。

具体过程即是：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。

目前有如下开源程序利用udp实现了可靠的数据传输。分别为RUDP、RTP、UDT:

1、RUDP（Reliable User Datagram Protocol）

RUDP 提供一组数据服务质量增强机制，如拥塞控制的改进、重发机制及淡化服务器算法等。

2、RTP（Real Time Protocol）

RTP为数据提供了具有实时特征的端对端传送服务，如在组播或单播网络服务下的交互式视频音频或模拟数据。

3、UDT（UDP-based Data Transfer Protocol）

UDT的主要目的是支持高速广域网上的海量数据传输。




### 四、HTTP（S）

#### 1. 简单介绍下 Https 的原理

**加密算法的类型基本上分为了两种**：

- 对称加密，加密用的密钥和解密用的密钥是同一个，比较有代表性的就是 AES 加密算法；

- 非对称加密，加密用的密钥称为公钥，解密用的密钥称为私钥，经常使用到的 RSA 加密算法就是非对称加密的；

此外，还有**Hash单向加密算法**：

- HASH算法：MD5, SHA1, SHA256

相比较对称加密而言，非对称加密安全性更高，但是加解密耗费的时间更长，速度慢。

HTTPS = HTTP + SSL，HTTPS 的加密就是在 SSL 中完成的。

这就要从 CA 证书讲起了。CA 证书其实就是数字证书，是由 CA 机构颁发的。至于 CA 机构的权威性，那么是毋庸置疑的，所有人都是信任它的。

**CA 证书内一般会包含以下内容**：

- 证书的颁发机构、版本

- 证书的使用者

- 证书的公钥

- 证书的有效时间

- 证书的数字签名 Hash 值和签名 Hash 算法

**客户端如何校验 CA 证书？**

- CA 证书中的 Hash 值，其实是用证书的私钥进行加密后的值（证书的私钥不在 CA 证书中）。然后客户端得到证书后，利用证书中的公钥去解密该 Hash 值，得到 Hash-a ；然后再利用证书内的签名 Hash 算法去生成一个 Hash-b 。最后比较 Hash-a 和 Hash-b 这两个的值。如果相等，那么证明了该证书是对的，服务端是可以被信任的；如果不相等，那么就说明该证书是错误的，可能被篡改了，浏览器会给出相关提示，无法建立起 HTTPS 连接。除此之外，还会校验 CA 证书的有效时间和域名匹配等。

**HTTPS 中的 SSL 握手建立过程**：

- 假设现在有客户端 A 和服务器 B ：

  - 1、首先，客户端 A 访问服务器 B ，比如我们用浏览器打开一个网页 [www.baidu.com](http://www.baidu.com/) ，这时，浏览器就是客户端 A ，百度的服务器就是服务器 B 了。这时候客户端 A 会生成一个随机数1，把随机数1 、自己支持的 SSL 版本号以及加密算法等这些信息告诉服务器 B 。

  - 2、服务器 B 知道这些信息后，然后确认一下双方的加密算法，然后服务端也生成一个随机数 2 ，并将随机数 2 和 CA 颁发给自己的证书一同返回给客户端 A 。

  - 3、客户端 A 得到 CA 证书后，会去校验该 CA 证书的有效性，校验方法在上面已经说过了。校验通过后，客户端生成一个随机数3 ，然后用证书中的公钥加密随机数3 并传输给服务端 B 。

  - 4、服务端 B 得到加密后的随机数3，然后利用私钥进行解密，得到真正的随机数3。

  - 5、最后，客户端 A 和服务端 B 都有随机数1、随机数2、随机数3，然后双方利用这三个随机数生成一个对话密钥。之后传输内容就是利用对话密钥来进行加解密了。这时就是利用了对称加密，一般用的都是 AES 算法。

  - 6、客户端 A 通知服务端 B ，指明后面的通讯用对话密钥来完成，同时通知服务器 B 客户端 A 的握手过程结束。

  - 7、服务端 B 通知客户端 A，指明后面的通讯用对话密钥来完成，同时通知客户端 A 服务器 B 的握手过程结束。

  - 8、SSL 的握手部分结束，SSL 安全通道的数据通讯开始，客户端 A 和服务器 B 开始使用相同的对话密钥进行数据通讯。

- 简化如下：

  - 1、客户端和服务端建立 SSL 握手，客户端通过 CA 证书来确认服务端的身份；

  - 2、互相传递三个随机数，之后通过这三个随机数来生成一个密钥；

  - 3、互相确认密钥，然后握手结束；

  - 4、数据通讯开始，都使用同一个对话密钥来加解密；

可以发现，在 HTTPS 加密原理的过程中把对称加密和非对称加密都利用了起来。即利用了非对称加密安全性高的特点，又利用了对称加密速度快，效率高的好处。

#### 2. HTTP是哪一层的协议，常见的HTTP状态码有哪些，分别代表什么意思？

HTTP协议是**应用层**的协议。

常见的HTTP状态码有：

| 类别  | 解释                                              |
| :---- | :------------------------------------------------ |
| `1xx` | 请求已经接收，继续处理                            |
| `2xx` | 服务器已经正确处理请求，比如`200`                 |
| `3xx` | 重定向，需要做进一步的处理才能完成请求            |
| `4xx` | 服务器无法理解的请求，比如`404`，访问的资源不存在 |
| `5xx` | 服务器收到请求以后，处理错误                      |

#### 3. HTTP 1.0 HTTP 1.1 和HTTP 2.0有什么区别？

HTTP1.0和HTTP1.1的一些区别：

HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

- 缓存处理：在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
- 带宽优化及网络连接的使用：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206，这样就方便了开发者自由的选择以便于充分利用带宽和连接。
- 错误通知的管理：在HTTP1.1中新增了24个错误状态响应码，如409表示请求的资源与资源的当前状态发生冲突；410表示服务器上的某个资源被永久性的删除。
- Host头处理：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误。
- 长连接：HTTP 1.1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启Connection： keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

HTTP 2.0基于HTTP 1.1，与HTTP 2.0增加了：

- 二进制格式：HTTP 1.1使用纯文本进行通信，HTTP 2.0使用二进制进行传输。

- Head压缩：对已经发送的Header使用键值建立索引表，相同的Header使用索引表示。

- 服务器推送：服务器可以进行主动推送

- 多路复用：一个TCP连接可以划分成多个流，每个流都会分配Id，客户端可以借助流和服务端建立全双工进行通信，并且流具有优先级。

  ![HTTP2连接](https://user-gold-cdn.xitu.io/2020/4/24/171ab7a74b1f877e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

#### 4. HTTP和HTTPS有什么区别？

简单来说，HTTP和HTTPS的关系是这样的

```
HTTPS = HTTP + SSL/TLS
```

> 注：TLS是SSL的升级替代版。

区别如下：

- HTTP作用于应用层，使用80端口，起始地址是`http://`，明文传输，消息容易被拦截，串改。

- HTTPS作用于传输层，使用443端口，起始地址是`https://`，需要下载CA证书，传输的过程需要加密，安全性高。



#### 5. SSL/TLS的握手过程？

![SSL/TLS](https://user-gold-cdn.xitu.io/2020/4/24/171ab7a751550e46?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)



#### 6. HTTPS传输过程中是如何处理进行加密的？为什么有对称加密的情况下仍然需要进行非对称加密？

过程和上图类似，依次获取证书，公钥，最后生成对称加密的钥匙进行对称加密。

- **对称加密**可以保证加密效率，但是不能解决密钥传输问题，用于数据传输阶段。

- **非对称加密**可以密钥解决传输问题，但是效率不高，用于连接建立阶段。

#### 7. HTTP的几种请求方法具体介绍？PUT和POST区别？

常见的有四种：

- `GET` 获取资源，没有body，幂等性
- `POST` 增加或者修改资源，有body，非幂等性
- `PUT` 修改资源，有body，幂等性
- `DELETE` 删除资源，幂等性

幂等性的方法:如果一个方法重复执行多次，产生的效果是一样的。

PUT请求：如果两个请求相同，后一个请求会把第一个请求覆盖掉。（所以PUT用来改资源）

POST请求：后一个请求不会把第一个请求覆盖掉。（所以Post用来增资源）

#### 8. HTTP请求和响应报文的格式，以及常用状态码?

1）请求报文：

请求行（request line）、请求头部（header）、空行和请求数据四个部分组成。

![image](https://user-gold-cdn.xitu.io/2020/3/1/17095bb261067fb2?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

请求行以一个方法符号开头，以空格分开，后面跟着请求的URI和协议的版本。

```
   //请求行（包括method、path、HTTP版本）
   GET /path HTTP/1.1
   //Headers
   Host: www.baidu.com
   Content-Type: text/plain
   //Body
   搜索****
```

2）响应报文

HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。

```
   //状态行 （包括HTTP版本、状态码，状态信息）
   HTTP/1.1 200 OK
   //Headers
   Content-Type: application/json; charset=utf-8
   //Body
   [{"info":"xixi"}]
```

3）常用状态码

主要分为五种类型：

- 1开头， 代表临时性消息，比如100（继续发送）
- 2开头， 代表请求成功，比如200（OK）
- 3开头， 代表重定向，比如304（内容无改变）
- 4开头， 代表客户端的一些错误，比如403（禁止访问）
- 5开头， 代表服务器的一些错误，比如500

#### 9. 介绍对称加密和非对称加密?

1）对称加密，即加密和解密算法不同，但是密钥相同。比如`DES，AES`算法。

```kotlin
数据A --> 算法D（密钥S）--> 加密数据B
加密数据B --> 算法E（密钥S）--> 数据A
```

优点：加/解密速度快、密钥管理简单、适宜一对一的信息加密传输，加密算法简单等。

缺点：密钥有可能被破解，容易被伪造。传输过程中一旦密钥被其他人获知则可以进行数据解密。

2）非对称加密，即加密和解密算法相同，但是密钥不同。私钥自己保存，公钥提供给对方。比如`RSA，DSA`算法。

```kotlin
数据A --> 算法D（公钥）--> 加密数据B
加密数据B --> 算法D（私钥）--> 数据A
```

优点：安全，公钥即使被其他人获知，也无法解密数据。

缺点：需要通信双方都有一套公钥和私钥。

#### 10. 数字签名的原理？

1）首先，为什么需要数字签名？

防止`被攻击，被伪造`。由于公钥是公开的，别人截获到公钥就能伪造数据进行传输，所以我们需要验证数据的来源。

2）怎么签名？

由于公钥能解密私钥加密的数据，私钥也能解密公钥加密的数据。

所以我们用公钥进行加密后，再用私钥进行一次加密，那么私钥的这次加密就叫`签名`，也就是只有我自己可以进行加密的操作。所以传输数据流程就变成了`加密数据和签名数据`，如果解出来都是同样的数据，那么则数据`安全可靠`。

```kotlin
数据A --> 算法D（公钥）--> 加密数据B
数据A --> 算法D（私钥）--> 签名数据C

加密数据B --> 算法D（私钥）--> 数据A
签名数据C --> 算法D（公钥）--> 数据A
```

#### 11. HTTPS 请求慢的解决办法?

- 不通过DNS解析，直接访问IP

- 解决连接无法复用

协议头里可以设置`Connection:Keep-Alive`或者`Connection:Close`，选择是否允许在一定时间内复用连接（时间可由服务器控制）。但是这对App端的请求成效不大，因为App端的请求比较分散且时间跨度相对较大。

方案1：

基于TCP的长连接移动端建立一条自己的长链接通道，通道的实现是基于tcp协议。基于tcp的socket编程技术难度相对复杂很多，而且需要自己定制协议。但信息的上报和推送变得更及时，请求量爆发的时间点还能减轻服务器压力（避免频繁创建和销毁连接）

方案2：

HTTP`long-polling` 客户端在初始状态发送一个polling请求到服务器，服务器并不会马上返回业务数据，而是等待有新的业务数据产生的时候再返回，所以链接会一直被保持。一但结束当前连接，马上又会发送一个新的polling请求，如此反复，保证一个连接被保持。 存在问题： 1）增加了服务器的压力 2）网络环境复杂场景下，需要考虑怎么重建健康的连接通道 3）polling的方式稳定性不好 4）polling的response可能被中间代理cache住 ……

方案3：

HTTP`streaming` 和long-polling不同的是，streaming方式通过再server response的头部增加“Transfer Encoding:chuncked”来告诉客户端后续还有新的数据到来 存在问题： 1）有些代理服务器会等待服务器的response结束之后才将结果推送给请求客户端。streaming不会结束response 2）业务数据无法按照请求分割 ……

方案4：

Web socket 和传统的Tcp socket相似，基于tcp协议，提供双向的数据通道。它的优势是提供了message的概念，比基于字节流的tcp socket使用更简单。技术较新，不是所有浏览器都提供了支持。

- 解决head of line blocking

它的原因是队列的第一个数据包（队头）受阻而导致整列数据包受阻，使用**http pipelining**，确保几乎在同一时间把request发向了服务器

#### 12. 谈谈对HTTP缓存的了解?

HTTP的缓存机制也是依赖于请求和响应header里的参数类实现的，最终响应式从缓存中去，还是从服务端重新拉取，HTTP的缓存机制的流程如下所示：

![image](https://user-gold-cdn.xitu.io/2020/3/1/17095bb2640cf9ab?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

HTTP的缓存可以分为两种：

强制缓存：需要服务端参与判断是否继续使用缓存，当客户端第一次请求数据是，服务端返回了缓存的过期时间（`Expires`与`Cache-Control`），没有过期就可以继续使用缓存，否则则不适用，无需再向服务端询问。

对比缓存：需要服务端参与判断是否继续使用缓存，当客户端第一次请求数据时，服务端会将缓存标识（`Last-Modified/If-Modified-Since与Etag/If-None-Match`）与数据一起返回给客户端，客户端将两者都备份到缓存中 ，再次请求数据时，客户端将上次备份的缓存 标识发送给服务端，服务端根据缓存标识进行判断，如果返回304，则表示通知客户端可以继续使用缓存。 强制缓存优先于对比缓存。

上面提到强制缓存使用的的两个标识：

`Expires`：Expires的值为服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。到期时间是服务端生成的，客户端和服务端的时间可能有误差。 `Cache-Control：Expires`有个时间校验的问题，所有HTTP1.1采用`Cache-Control`替代Expires。

 `Cache-Control`的取值有以下几种：

- `private`: 客户端可以缓存。

- `public`: 客户端和代理服务器都可缓存。

- `max-age=xxx`: 缓存的内容将在 xxx 秒后失效。

- `no-cache`: 需要使用对比缓存来验证缓存数据。

- `no-store`: 所有内容都不会缓存，强制缓存，对比缓存都不会触发。 我们再来看看对比缓存的两个标识：

**Last-Modified/If-Modified-Since**

`Last-Modified` 表示资源上次修改的时间。

当客户端发送第一次请求时，服务端返回资源上次修改的时间：

```
Last-Modified: Tue, 12 Jan 2016 09:31:27 GMT
```

客户端再次发送，会在header里携带`If-Modified-Since`。将上次服务端返回的资源时间上传给服务端。

```
If-Modified-Since: Tue, 12 Jan 2016 09:31:27 GMT 
```

服务端接收到客户端发来的资源修改时间，与自己当前的资源修改时间进行对比，如果自己的资源修改时间大于客户端发来的资源修改时间，则说明资源做过修改， 则返回200表示需要重新请求资源，否则返回304表示资源没有被修改，可以继续使用缓存。

上面是一种时间戳标记资源是否修改的方法，还有一种资源标识码`ETag`的方式来标记是否修改，如果标识码发生改变，则说明资源已经被修改，`ETag`优先级高于`Last-Modified`。

```
Etag/If-None-Match
```

`ETag`是资源文件的一种标识码，当客户端发送第一次请求时，服务端会返回当前资源的标识码：

```
ETag: "5694c7ef-24dc"
```

客户端再次发送，会在header里携带上次服务端返回的资源标识码：

`If-None-Match`: "5694c7ef-24dc" 服务端接收到客户端发来的资源标识码，则会与自己当前的资源吗进行比较，如果不同，则说明资源已经被修改，则返回200，如果相同则说明资源没有被修改，返回 304，客户端可以继续使用缓存。

#### 13. HTTP长连接?

Http1.0是短连接，HTTP1.1默认是长连接，也就是默认Connection的值就是keep-alive。但是长连接实质是指的TCP连接，而不是HTTP连接。TCP连接是一个双向的通道，它是可以保持一段时间不关闭的，因此TCP连接才有真正的长连接和短连接这一说。

**Http1.1为什么要用使用tcp长连接？**

长连接是指的TCP连接，也就是说复用的是TCP连接。即长连接情况下，多个HTTP请求可以复用同一个TCP连接，这就节省了很多TCP连接建立和断开的消耗。

此外，长连接并不是永久连接的。如果一段时间内（具体的时间长短，是可以在header当中进行设置的，也就是所谓的超时时间），这个连接没有HTTP请求发出的话，那么这个长连接就会被断掉。

#### 14. HTTPS 如何防范中间人攻击？

**什么是中间人攻击？**

当数据传输发生在一个设备（PC/手机）和网络服务器之间时，攻击者使用其技能和工具将自己置于两个端点之间并截获数据；尽管交谈的两方认为他们是在与对方交谈，但是实际上他们是在与干坏事的人交流，这便是中间人攻击。

**有几种攻击方式？**

- 1、嗅探：

嗅探或数据包嗅探是一种用于捕获流进和流出系统/网络的数据包的技术。网络中的数据包嗅探就好像电话中的监听。

- 2、数据包注入：

在这种技术中，攻击者会将恶意数据包注入常规数据中。这样用户便不会注意到文件/恶意软件，因为它们是合法通讯流的一部分。

- 3、会话劫持：

在你登录进你的银行账户和退出登录这一段期间便称为一个会话。这些会话通常都是黑客的攻击目标，因为它们包含潜在的重要信息。在大多数案例中，黑客会潜伏在会话中，并最终控制它。

- 4、SSL剥离：

在SSL剥离攻击中，攻击者使SSL/TLS连接剥落，随之协议便从安全的HTTPS变成了不安全的HTTP。

**HTTPS 如何防范中间人攻击?**

请见https加密原理。




### 五、Socket

#### 1. socket断线重连怎么实现，心跳机制又是怎样实现？

**socket概念**

套接字（socket）是通信的基石，是支持TCP/IP协议的网络通信的基本操作单元。它是网络通信过程中端点的抽象表示，包含进行网络通信必须的五种信息：连接使用的协议，本地主机的IP地址，本地进程的协议端口，远地主机的IP地址，远地进程的协议端口。

为了区别不同的应用程序进程和连接，许多计算机操作系统为应用程序与TCP／IP协议交互提供了套接字(Socket)接口。应 用层可以和传输层通过Socket接口，区分来自不同应用程序进程或网络连接的通信，实现数据传输的并发服务。

**建立socket连接**

建立Socket连接至少需要一对套接字，其中一个运行于客户端，称为ClientSocket ，另一个运行于服务器端，称为ServerSocket 。

套接字之间的连接过程分为三个步骤：服务器监听，客户端请求，连接确认。

- 服务器监听：服务器端套接字并不定位具体的客户端套接字，而是处于等待连接的状态，实时监控网络状态，等待客户端的连接请求。
- 客户端请求：指客户端的套接字提出连接请求，要连接的目标是服务器端的套接字。为此，客户端的套接字必须首先描述它要连接的服务器的套接字，指出服务器端- - 套接字的地址和端口号，然后就向服务器端套接字提出连接请求。

连接确认：当服务器端套接字监听到或者说接收到客户端套接字的连接请求时，就响应客户端套接字的请求，建立一个新的线程，把服务器端套接字的描述发 给客户端，一旦客户端确认了此描述，双方就正式建立连接。而服务器端套接字继续处于监听状态，继续接收其他客户端套接字的连接请求。

**Socket连接与TCP连接**

创建Socket连接时，可以指定使用的传输层协议，Socket可以支持不同的传输层协议（TCP或UDP），当使用TCP协议进行连接时，该Socket连接就是一个TCP连接。

**Socket连接与HTTP连接**

由于通常情况下Socket连接就是TCP连接，因此Socket连接一旦建立，通信双方即可开始相互发送数据内容，直到双方连接断开。但在实际网 络应用中，客户端到服务器之间的通信往往需要穿越多个中间节点，例如路由器、网关、防火墙等，大部分防火墙默认会关闭长时间处于非活跃状态的连接而导致 Socket 连接断连，因此需要通过轮询告诉网络，该连接处于活跃状态。

而HTTP连接使用的是“请求—响应”的方式，不仅在请求时需要先建立连接，而且需要客户端向服务器发出请求后，服务器端才能回复数据。

很多情况下，需要服务器端主动向客户端推送数据，保持客户端与服务器数据的实时与同步。此时若双方建立的是Socket连接，服务器就可以直接将数 据传送给客户端；若双方建立的是HTTP连接，则服务器需要等到客户端发送一次请求后才能将数据传回给客户端，因此，客户端定时向服务器端发送连接请求， 不仅可以保持在线，同时也是在“询问”服务器是否有新的数据，如果有就将数据传给客户端。TCP(Transmission Control Protocol)　传输控制协议

**Socket断线重连实现**

正常连接断开客户端会给服务端发送一个fin包，服务端收到fin包后才会知道连接断开。 而断网断电时客户端无法发送fin包给服务端，所以服务端没办法检测到客户端已经短线。 为了缓解这个问题，服务端需要有个心跳逻辑，就是服务端检测到某个客户端多久没发送任何数据过来就认为客户端已经断开， 这需要客户端定时向服务端发送心跳数据维持连接。

**心跳机制实现**

长连接的实现：心跳机制，应用层协议大多都有HeartBeat机制，通常是客户端每隔一小段时间向服务器发送一个数据包，通知服务器自己仍然在线。并传输一些可能必要的数据。使用心跳包的典型协议是IM，比如QQ/MSN/飞信等协议

1、在TCP的机制里面，本身是存在有心跳包的机制的，也就是TCP的选项：SO_KEEPALIVE。 系统默认是设置的2小时的心跳频率。但是它检查不到机器断电、网线拔出、防火墙这些断线。 而且逻辑层处理断线可能也不是那么好处理。一般，如果只是用于保活还是可以的。通过使用TCP的KeepAlive机制（修改那个time参数），可以让连接每隔一小段时间就产生一些ack包，以降低被踢掉的风险，当然，这样的代价是额外的网络和CPU负担。

2、应用层心跳机制实现。





### 六、DNS



### 七、IP

#### 1. IP报文中的内容。

![image](https://user-gold-cdn.xitu.io/2020/3/1/17095bb26436e98e?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

版本：IP协议的版本，目前的IP协议版本号为4，下一代IP协议版本号为6。

首部长度：IP报头的长度。固定部分的长度（20字节）和可变部分的长度之和。共占4位。最大为1111，即10进制的15，代表IP报头的最大长度可以为15个32bits（4字节），也就是最长可为15*4=60字节，除去固定部分的长度20字节，可变部分的长度最大为40字节。

服务类型：Type Of Service。

总长度：IP报文的总长度。报头的长度和数据部分的长度之和。

标识：唯一的标识主机发送的每一分数据报。通常每发送一个报文，它的值加一。当IP报文长度超过传输网络的MTU（最大传输单元）时必须分片，这个标识字段的值被复制到所有数据分片的标识字段中，使得这些分片在达到最终目的地时可以依照标识字段的内容重新组成原先的数据。

标志：共3位。R、DF、MF三位。目前只有后两位有效，DF位：为1表示不分片，为0表示分片。MF：为1表示“更多的片”，为0表示这是最后一片。

片位移：本分片在原先数据报文中相对首位的偏移位。（需要再乘以8）

生存时间：IP报文所允许通过的路由器的最大数量。每经过一个路由器，TTL减1，当为0时，路由器将该数据报丢弃。TTL 字段是由发送端初始设置一个 8 bit字段.推荐的初始值由分配数字 RFC 指定，当前值为 64。发送 ICMP 回显应答时经常把 TTL 设为最大值 255。

协议：指出IP报文携带的数据使用的是那种协议，以便目的主机的IP层能知道要将数据报上交到哪个进程（不同的协议有专门不同的进程处理）。和端口号类似，此处采用协议号，TCP的协议号为6，UDP的协议号为17。ICMP的协议号为1，IGMP的协议号为2.

首部校验和：计算IP头部的校验和，检查IP报头的完整性。

源IP地址：标识IP数据报的源端设备。

目的IP地址：标识IP数据报的目的地址。

最后就是可变部分和数据部分。



### 八、其他

#### 1. Cookie与Session的作用和原理。

- Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中。
- Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。

**Session**

由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车，当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的。

具体到Web中的Session指的就是用户在浏览某个网站时，从进入网站到浏览器关闭所经过的这段时间，也就是用户浏览这个网站所花费的时间。因此从上述的定义中我们可以看到，Session实际上是一个特定的时间概念。

当客户端访问服务器时，服务器根据需求设置Session，将会话信息保存在服务器上，同时将标示Session的SessionId传递给客户端浏览器，

浏览器将这个SessionId保存在内存中，我们称之为无过期时间的Cookie。浏览器关闭后，这个Cookie就会被清掉，它不会存在于用户的Cookie临时文件。

以后浏览器每次请求都会额外加上这个参数值，服务器会根据这个SessionId，就能取得客户端的数据信息。

如果客户端浏览器意外关闭，服务器保存的Session数据不是立即释放，此时数据还会存在，只要我们知道那个SessionId,就可以继续通过请求获得此Session的信息，因为此时后台的Session还存在，当然我们可以设置一个Session超时时间，一旦超过规定时间没有客户端请求时，服务器就会清除对应SessionId的Session信息。

**Cookie**

Cookie是由服务器端生成，发送给User-Agent（一般是web浏览器），浏览器会将Cookie的key/value保存到某个目录下的文本文件内，下次请求同一网站时就发送该Cookie给服务器（前提是浏览器设置为启用Cookie）。Cookie名称和值可以由服务器端开发自己定义，对于JSP而言也可以直接写入Sessionid，这样服务器可以知道该用户是否合法用户以及是否需要重新登录等。



## 计算机基础

### 一、加密算法

#### 1. 有用过什么加密算法？AES,RAS什么原理？

**DES加密算法**

**1.DES含义**

DES全称为Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法。

DES是对称性加密里常见的一种，是一种使用秘钥加密的块算法。秘钥长度是64位（bit）， 超过位数秘钥被忽略。所谓对称性加密，加密和解密秘钥相同。对称性加密一般会按照固定长度，把待加密字符串分成块。不足一整块或者刚好最后有特殊填充字符。

常见的填充模式有：'pkcs5'、'pkcs7'、'iso10126'、'ansix923'、'zero' 类型，包括DES-ECB、DES-CBC、DES-CTR、DES-OFB、DES-CFB。

**2. DES算法原理**

DES算法的入口参数：Key、Data、Mode。

Key为8个字节共64位，是DES算法的工作秘钥；

Data也为8个字节64位，是要被加密或解密的数据；

Mode为DES的工作方式，有两种：加密或解密。

 ![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy9qdTFEenFYOGlhT2sxeVAwRTVwU3BMbzgyOUtiUkdOc2lhUEVYU1dXY25yUWljU0xDN1VmYXFpYmtEMG15UVVMSmFaaWFjRFB2QUlBejFjdE1pYWgxMWljTUpYc1EvNjQw?x-oss-process=image/format,png)

**3.DES加密原理**

DES 使用一个 56 位的密钥以及附加的 8 位奇偶校验位，产生最大 64 位的分组大小。这是一个迭代的分组密码，使用称为 Feistel 的技术，其中将加密的文本块分成两半。

使用子密钥对其中一半应用循环功能，然后将输出与另一半进行“异或”运算；接着交换这两半，这一过程会继续下去，但最后一个循环不交换。DES 使用 16 个循环，使用异或，置换，代换，移位操作四种基本运算。

**4.DES算法特点**

分组比较短、秘钥太短、密码生命周期短、运算速度较慢。

**AES加密算法**

**1.AES含义**

AES，高级加密标准，在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES，已经被多方分析且广为全世界所使用。

严格地说，AES和Rijndael加密法并不完全一样（虽然在实际应用中二者可以互换），因为Rijndael加密法可以支持更大范围的区块和密钥长度：AES的区块长度固定为128 比特，密钥长度则可以是128，192或256比特；

而Rijndael使用的密钥和区块长度可以是32位的整数倍，以128位为下限，256比特为上限。包括AES-ECB，AES-CBC，AES-CTR，AES-OFB，AES-CFB。

**2.AES加密原理**

AES加密过程涉及到4种操作，分别是字节替代、行移位、列混淆和轮密钥加。解密过程分别为对应的逆操作。由于每一步操作都是可逆的，按照相反的顺序进行解密即可恢复明文。加解密中每轮的密钥分别由初始密钥扩展得到。算法中16个字节的明文、密文和轮密钥都以一个4x4的矩阵表示。

**3.AES算法特点**

运算速度快，安全性高，资源消耗少

**RSA加密算法**

**1.RSA含义**

RSA加密算法是一种非对称加密算法，这种算法非常可靠，密钥越长，它就越难破解。根据已经披露的文献，目前被破解的最长RSA密钥是768个二进制位。

也就是说，长度超过768位的密钥，还无法破解（至少没人公开宣布）。因此可以认为，1024位的RSA密钥基本安全，2048位的密钥极其安全。

**2.RSA算法原理**

在了解RSA算法原理之前，先了解一下非对称加密的过程：

非对称加密是通过两个密钥（公钥-私钥）来实现对数据的加密和解密的。公钥用于加密，私钥用于解密。对于非对称的加密和解密为什么可以使用不同的密钥来进行，这些都是数学上的问题了。不同的非对称加密算法也会应用到不同的数学知识。接下来就来看看RSA算法是怎么来对数据进行加密的。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy9qdTFEenFYOGlhT2sxeVAwRTVwU3BMbzgyOUtiUkdOc2lhMlV5SnVhaE1DSUxrSnQ3c2prUldTcGViYVF6emlhT3FKcmgzVFBRcTg2UWt5M0VEa0d0cUtQUS82NDA?x-oss-process=image/format,png)

下面是RSA算法的加密算法流程图：

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL3N6X21tYml6X3BuZy9qdTFEenFYOGlhT2sxeVAwRTVwU3BMbzgyOUtiUkdOc2lhc1hSbFZUZkFQeWd4SHFtbllMV1c5WjFIRHhnZ3pNak5GaWFoRVd4UndUM1N3SHJuQ0pBWGFnUS82NDA?x-oss-process=image/format,png)

**3.RSA算法特点**

- 不需要进行密钥传递，提高了安全性
- 可以进行数字签名认证
- 加密解密效率不高，一般只适用于处理小量数据（如：密钥）
- 容易遭受小指数攻击

#### 2. Base64算法是什么，是加密算法吗？

- `Base64`是一种将二进制数据转换成64种字符组成的字符串的编码算法，主要用于非文本数据的传输，比如图片。可以将图片这种二进制数据转换成具体的字符串，进行保存和传输。
- 严格来说，不算。虽然它确实把一段二进制数据转换成另外一段数据，但是他的加密和解密是公开的，也就无秘密可言了。所以我更倾向于认为它是一种编码，每个人都可以用base64对二进制数据进行编码和解码。
- `面试加分项`：为了减少混淆，方便复制，减少数据长度，就衍生出一种base58编码。去掉了base64中一些容易混淆的数字和字母（数字0，字母O，字母I，数字1，符号+，符号/）
  大名鼎鼎的比特币就是用的改进后的base58编码，即`Base58Check`编码方式，有了校验机制，加入了hash值。

#### 3. Base64底层

Base64的原理比较简单，每当我们使用Base64时都会先定义一个类似这样的数组：

```
['A', 'B', 'C', ... 'a', 'b', 'c', ... '0', '1', ... '+', '/']
```

上面就是Base64的索引表，字符选用了"A-Z、a-z、0-9、+、/" 64个可打印字符，这是标准的Base64协议规定。在日常使用中我们还会看到“=”或“==”号出现在Base64的编码结果中，“=”在此是作为填充字符出现。

- 第一步，将待转换的字符串每三个字节分为一组，每个字节占8bit，那么共有24个二进制位。
- 第二步，将上面的24个二进制位每6个一组，共分为4组。
- 第三步，在每组前面添加两个0，每组由6个变为8个二进制位，总共32个二进制位，即四个字节。
- 第四步，根据Base64编码对照表（见下图）获得对应的值。

```
0　A　　17　R　　　34　i　　　51　z
1　B　　18　S　　　35　j　　　52　0
2　C　　19　T　　　36　k　　　53　1
3　D　　20　U　　　37　l　　　54　2
4　E　　21　V　　　38　m　　　55　3
5　F　　22　W　　　39　n　　　56　4
6　G　　23　X　　　40　o　　　57　5
7　H　　24　Y　　　41　p　　　58　6
8　I　　25　Z　　　42　q　　　59　7
9　J　　26　a　　　43　r　　　60　8
10　K　　27　b　　　44　s　　　61　9
11　L　　28　c　　　45　t　　　62　+
12　M　　29　d　　　46　u　　　63　/
13　N　　30　e　　　47　v
14　O　　31　f　　　48　w　　　
15　P　　32　g　　　49　x
16　Q　　33　h　　　50　y
```

从上面的步骤我们发现：

- Base64字符表中的字符原本用6个bit就可以表示，现在前面添加2个0，变为8个bit，会造成一定的浪费。因此，Base64编码之后的文本，要比原文大约三分之一。
- 为什么使用3个字节一组呢？因为6和8的最小公倍数为24，三个字节正好24个二进制位，每6个bit位一组，恰好能够分为4组。

如果字节数不足三个:

- 两个字节：两个字节共16个二进制位，依旧按照规则进行分组。此时总共16个二进制位，每6个一组，则第三组缺少2位，用0补齐，得到三个Base64编码，第四组完全没有数据则用“=”补上。因此，上图中“BC”转换之后为“QKM=”；
- 一个字节：一个字节共8个二进制位，依旧按照规则进行分组。此时共8个二进制位，每6个一组，则第二组缺少4位，用0补齐，得到两个Base64编码，而后面两组没有对应数据，都用“=”补上。因此，上图中“A”转换之后为“QQ==”；

Base64就是用6位（2的6次幂就是64）表示字符，因此成为Base64。同理，Base32就是用5位，Base16就是用4位。

### 二、数据库 

#### 1. 数据库的四大特征，数据库的隔离级别？

事务（Transaction）是并发控制的基本单位。所谓的事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。例如，银行转账工作：从一个账号扣款并使另一个账号增款，这两个操作要么都执行，要么都不执行。所以，应该把它们看成一个事务。事务是数据库维护数据一致性的单位，在每个事务结束时，都能保持数据一致性。事务具有以下4个基本特征：

数据库的四大特征：

（1）原子性（Atomicity）

原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚。

（2）一致性（Consistency）

一个事务执行之前和执行之后都必须处于一致性状态。

（3）隔离性（Isolation）

隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。

（4）持久性（Durability）

持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的。

数据库的隔离级别：

1）Serializable(串行化)：可避免脏读、不可重复读、幻读的发生。

2）Repeatable read (可重复读)：可避免脏读、不可重复读的发生。

3）Read committed (读已提交)：可避免脏读的发生。

4）Read uncommitted (读未提交)：最低级别，任何情况都无法保证。

#### 2. 数据库设计中常讲的三范式是指什么？

1）第一范式1NF(域的原子性)

如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式

2）第二范式2NF(表中除主键外的字段都完全依赖主键)

第二范式是在第一范式基础上建立的。第二范式有两个重点:

(1)表中必须有主键

(2)其他非主属性必须完全依赖主键，不能只依赖主键的一部分（主要针对联合主键而言）。

3）第三范式3NF（表中除主键外的字段都完全直接依赖，不能是传递依赖）

不能是传递依赖，即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。第二范式和第三范式区分的关键点：2NF：非主键列是否完全依赖于主键，还是依赖于主键的一部分；3NF：非主键列是直接依赖于主键，还是直接依赖于非主键列。





## 操作系统

### 一、进程与线程

#### 1. 说下Linux进程和线程的区别?

进程和线程的主要差别在于它们是不同的操作系统资源管理方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个进程死掉就等于所有线程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。但对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。

- 简而言之,一个程序至少有一个进程,一个进程至少有一个线程。

- 线程的划分尺度小于进程，使得多线程程序的并发性高。

- 另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。

- 线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。

- 从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。

### 二、内存管理



### 三、文件管理

#### 1. 解释一下Linux的软链接和硬链接吗？

Linux链接分两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。

**硬连接**

硬连接指通过索引节点来进行连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件真正删除的条件是与之相关的所有硬连接文件均被删除。

**软连接**

另外一种连接称之为符号连接（Symbolic Link），也叫软连接。软链接文件有类似于Windows的快捷方式。它实际上是一个特殊的文件。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。

